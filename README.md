
# Contour Based Semantic Segmentation for RBC Morphology Analysis
ğŸš€ *Pixel-wise Red Blood Cell (RBC) Segmentation using UNet for Morphological Anemia Analysis*

---

## ğŸ“Œ Project Overview

This project focuses on building a **deep learning-based pipeline** to segment red blood cells (RBCs) from blood smear images. The primary goal is to isolate individual RBCs using **semantic segmentation**, enabling downstream analysis such as cell classification and morphological diagnosis of anemia.

The model is designed using a **UNet architecture**, optimized for **pixel-wise mask prediction** on binary images. This phase is the foundation for further feature extraction and classification of anemia types.

---

## ğŸ§¬ Objective

To detect and isolate RBCs from binary blood smear images to support classification into:

- ğŸ”´ **Normocytes** â€“ Normal-sized, round RBCs with central pallor  
- ğŸ”µ **Microcytes** â€“ Small RBCs, often present in iron deficiency anemia  
- ğŸŸ  **Macrocytes** â€“ Large RBCs, associated with B12/folate deficiency  
- ğŸŸ£ **Elliptocytes** â€“ Oval-shaped RBCs, common in hereditary elliptocytosis  
- ğŸ¯ **Target Cells** â€“ RBCs with a bullseye-like appearance, seen in thalassemia/liver disease

---

## ğŸ“‚ Dataset

- **Source**: AneRBC-II Dataset (Open-access)  
- **Total Images**: 36,000  
  - 18,000 from **Anemic** patients  
  - 18,000 from **Healthy** individuals  
- Each category contains:
  - `Original_images/`: Raw microscope images  
  - `Binary_segmented/`: Black RBCs on white background (used for training)  
  - `RGB_segmented/`: Color-isolated RBCs  
- **Preprocessing**:
  - Resized all images to **224Ã—224** to match model input requirements

---

## ğŸ”¬ Phase 1: Semantic Segmentation using UNet

### ğŸ§  Why UNet?

UNet is a **fully convolutional network** designed for biomedical image segmentation. It excels at **pixel-level labeling** using a **U-shaped encoderâ€“decoder architecture** with **skip connections**. This allows the model to learn **contextual features (what)** and **spatial localization (where)** simultaneously.

---

### ğŸ— UNet Architecture (Used in This Project)

- **Input shape**: `(224, 224, 1)` â€“ grayscale binary images
- **Output**: Single-channel binary mask (pixel values in range [0, 1])
- **Total Conv2D Layers**: 14
- **Pooling/Upsampling Layers**: 3 each
- **Skip Connections**: Between each encoder and corresponding decoder layer

#### ğŸ”» Encoder (Contracting Path):
1. Conv2D â†’ ReLU â†’ Conv2D â†’ ReLU  
2. MaxPooling2D (downsampling)
3. Repeated 3 times, doubling filters at each stage (64 â†’ 128 â†’ 256)

#### ğŸ¯ Bottleneck:
- 2 Conv2D layers with 512 filters

#### ğŸ”¼ Decoder (Expanding Path):
1. UpSampling2D â†’ Concatenate skip connection  
2. Conv2D â†’ ReLU â†’ Conv2D â†’ ReLU  
3. Repeated 3 times, reducing filters each time (256 â†’ 128 â†’ 64)

#### ğŸ§¾ Output Layer:
- Final Conv2D (1Ã—1 kernel) with Sigmoid activation to predict per-pixel probability

---

## âš™ï¸ Training Configuration

- **Loss Function**:  
  - `Binary Crossentropy` â†’ for pixel-level classification  
  - `Dice Loss` â†’ to maximize mask overlap (especially important due to class imbalance)

- **Optimizer**:  
  - `Adam` (Adaptive Moment Estimation)  
  - Chosen for its speed and adaptive learning rate capabilities

- **Batch Size**: 32  
- **Epochs**: 10  
- **Validation Split**: 20%

---

## ğŸ“Š Results & Performance

| Metric             | Value     |
|--------------------|-----------|
| Training Accuracy  | 99.80%    |
| Validation Accuracy| 89.64%    |
| Mean IoU (Val)     | ~0.30     |

### ğŸ§ª Visual Output:
- Masks showed clear, crisp RBC boundaries  
- RBCs remained separated in most cases  
- Minimal merging, even in dense cell clusters  
- Average ~16â€“20 cells segmented per image

---

## âŒ Dropped Methods

### ğŸ”» Mean Shift Segmentation
- Initially applied to CLAHE-enhanced RGB images using `cv2.pyrMeanShiftFiltering()`
- **Dropped due to**:
  - High computational cost
  - Tendency to merge overlapping RBCs
  - Inefficiency on large-scale datasets

### ğŸ”» CLAHE (Binary)
- Applied CLAHE only to RGB images for visual enhancement  
- **Skipped for binary inputs** due to already strong contrast

---

## ğŸ”œ Future Plans ?

With successful segmentation completed, the next phase can be:

- âœ‚ï¸ **Cropping** each segmented RBC from original images  
- ğŸ“ **Feature Extraction**:
  - Shape: area, eccentricity, circularity  
  - Texture: entropy, contrast  
  - Color (if using RGB): mean hue, saturation  
- ğŸ§  **Classification** of RBCs using a CNN or MLP classifier trained on these features

---
